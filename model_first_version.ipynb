{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":120777,"databundleVersionId":14442495,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":14073301,"sourceType":"datasetVersion","datasetId":8958389}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install seqeval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T16:19:47.449356Z","iopub.execute_input":"2025-12-08T16:19:47.449623Z","iopub.status.idle":"2025-12-08T16:19:56.735497Z","shell.execute_reply.started":"2025-12-08T16:19:47.449601Z","shell.execute_reply":"2025-12-08T16:19:56.734581Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-08T16:19:56.737787Z","iopub.execute_input":"2025-12-08T16:19:56.738778Z","iopub.status.idle":"2025-12-08T16:19:57.003548Z","shell.execute_reply.started":"2025-12-08T16:19:56.738739Z","shell.execute_reply":"2025-12-08T16:19:57.002816Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nSTART LOADING DATA\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T16:19:57.004291Z","iopub.execute_input":"2025-12-08T16:19:57.004693Z","iopub.status.idle":"2025-12-08T16:19:57.008833Z","shell.execute_reply.started":"2025-12-08T16:19:57.004664Z","shell.execute_reply":"2025-12-08T16:19:57.008085Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/ass4-smalldf/train.csv\")[:1000]\nval_df = pd.read_csv(\"/kaggle/input/ass4-smalldf/val.csv\")[:500]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T16:19:57.010207Z","iopub.execute_input":"2025-12-08T16:19:57.010390Z","iopub.status.idle":"2025-12-08T16:20:29.214387Z","shell.execute_reply.started":"2025-12-08T16:19:57.010375Z","shell.execute_reply":"2025-12-08T16:20:29.213557Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nEND LOADING DATA\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T16:20:29.216530Z","iopub.execute_input":"2025-12-08T16:20:29.216732Z","iopub.status.idle":"2025-12-08T16:20:29.220830Z","shell.execute_reply.started":"2025-12-08T16:20:29.216716Z","shell.execute_reply":"2025-12-08T16:20:29.220039Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import Dataset\n\ndef array_to_str(x):\n    if isinstance(x, list):\n        return x\n    if isinstance(x, np.ndarray):\n        return x.tolist()\n    if isinstance(x, str):\n        s = x.strip()\n        if s.startswith(\"[\") and s.endswith(\"]\"):\n            s = s[1:-1]\n            s = s.strip()\n            if not s:\n                return []\n            parts = s.split()\n            try:\n                return [int(p) for p in parts]\n            except ValueError:\n                return x\n    return x\n\nfor df in (train_df, val_df):\n    for col in df.columns:\n        if df[col].dtype == \"object\":\n            first_val = df[col].iloc[0]\n            if isinstance(first_val, str):\n                fs = first_val.strip()\n                if fs.startswith(\"[\") and fs.endswith(\"]\"):\n                    df[col] = df[col].apply(array_to_str)\n\ntrain_dataset = Dataset.from_pandas(train_df.reset_index(drop=True))\nval_dataset = Dataset.from_pandas(val_df.reset_index(drop=True))\n\nwanted_cols = [c for c in [\"input_ids\", \"attention_mask\", \"token_type_ids\", \"labels\"] if c in train_dataset.column_names]\nextra_cols = [c for c in train_dataset.column_names if c not in wanted_cols]\nif extra_cols:\n    train_dataset = train_dataset.remove_columns(extra_cols)\n    val_dataset = val_dataset.remove_columns(extra_cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T16:20:29.221630Z","iopub.execute_input":"2025-12-08T16:20:29.222201Z","iopub.status.idle":"2025-12-08T16:20:36.538419Z","shell.execute_reply.started":"2025-12-08T16:20:29.222184Z","shell.execute_reply":"2025-12-08T16:20:36.537610Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_name = \"microsoft/mdeberta-v3-base\" # mDeBERTa-v3\n\nlabel_list = [\"O\", \"S-LOC\", \"I-LOC\"]\n\nid2label = {i: label for i, label in enumerate(label_list)}\nlabel2id = {label: i for i, label in enumerate(label_list)}\n\nbatch_size = 4\nepochs = 2\nlr = 3e-5\nnum_labels = len(label_list)\npadding = -100\nmax_len = 512","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T16:20:36.540080Z","iopub.execute_input":"2025-12-08T16:20:36.540445Z","iopub.status.idle":"2025-12-08T16:20:36.544857Z","shell.execute_reply.started":"2025-12-08T16:20:36.540426Z","shell.execute_reply":"2025-12-08T16:20:36.544303Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(model_name) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T16:20:36.545678Z","iopub.execute_input":"2025-12-08T16:20:36.545963Z","iopub.status.idle":"2025-12-08T16:20:49.536775Z","shell.execute_reply.started":"2025-12-08T16:20:36.545940Z","shell.execute_reply":"2025-12-08T16:20:49.535954Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoModelForTokenClassification\n\nmodel = AutoModelForTokenClassification.from_pretrained(\n    model_name,\n    num_labels=num_labels,\n    id2label=id2label,\n    label2id=label2id,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T16:20:49.537730Z","iopub.execute_input":"2025-12-08T16:20:49.538553Z","iopub.status.idle":"2025-12-08T16:21:26.695893Z","shell.execute_reply.started":"2025-12-08T16:20:49.538532Z","shell.execute_reply":"2025-12-08T16:21:26.695278Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import DataCollatorForTokenClassification\n\ndata_collator = DataCollatorForTokenClassification(\n    tokenizer=tokenizer,\n    label_pad_token_id=padding,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T16:21:26.696633Z","iopub.execute_input":"2025-12-08T16:21:26.697403Z","iopub.status.idle":"2025-12-08T16:21:26.775554Z","shell.execute_reply.started":"2025-12-08T16:21:26.697369Z","shell.execute_reply":"2025-12-08T16:21:26.774924Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom seqeval.metrics import f1_score, precision_score, recall_score\n\ndef compute_metrics(eval_pred):\n    true_tags = []\n    pred_tags = []\n\n    id2label_local = id2label\n\n    logits, labels = eval_pred\n    preds = np.argmax(logits, axis=-1)\n    \n    for p_seq, l_seq in zip(preds, labels):\n        t_seq = []\n        p_tags = []\n        \n        for p, l in zip(p_seq, l_seq):\n            if l == -100:\n                continue\n                \n            t_seq.append(id2label_local[l])\n            p_tags.append(id2label_local[p])\n            \n        true_tags.append(t_seq)\n        pred_tags.append(p_tags)\n\n    return {\n        \"precision\": precision_score(true_tags, pred_tags),\n        \"recall\": recall_score(true_tags, pred_tags),\n        \"f1\": f1_score(true_tags, pred_tags),\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T16:21:26.776407Z","iopub.execute_input":"2025-12-08T16:21:26.776707Z","iopub.status.idle":"2025-12-08T16:21:26.850886Z","shell.execute_reply.started":"2025-12-08T16:21:26.776662Z","shell.execute_reply":"2025-12-08T16:21:26.850240Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    output_dir=\"./ner-mdeberta-v3\",\n    learning_rate=lr,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=epochs,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    logging_steps=100,\n    report_to=\"none\",  \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T16:21:26.851714Z","iopub.execute_input":"2025-12-08T16:21:26.851979Z","iopub.status.idle":"2025-12-08T16:21:30.673387Z","shell.execute_reply.started":"2025-12-08T16:21:26.851961Z","shell.execute_reply":"2025-12-08T16:21:30.672738Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nSTART TRAINING MODEL\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T16:21:30.674210Z","iopub.execute_input":"2025-12-08T16:21:30.674457Z","iopub.status.idle":"2025-12-08T16:21:30.678649Z","shell.execute_reply.started":"2025-12-08T16:21:30.674431Z","shell.execute_reply":"2025-12-08T16:21:30.678100Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T16:21:30.682094Z","iopub.execute_input":"2025-12-08T16:21:30.682429Z","iopub.status.idle":"2025-12-08T16:22:45.745483Z","shell.execute_reply.started":"2025-12-08T16:21:30.682407Z","shell.execute_reply":"2025-12-08T16:22:45.744635Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nEND TRAINING MODE\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T16:22:45.746399Z","iopub.execute_input":"2025-12-08T16:22:45.746682Z","iopub.status.idle":"2025-12-08T16:22:45.751811Z","shell.execute_reply.started":"2025-12-08T16:22:45.746659Z","shell.execute_reply":"2025-12-08T16:22:45.750889Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/kse-ua-location-extraction-2025/test.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T16:22:45.752755Z","iopub.execute_input":"2025-12-08T16:22:45.752990Z","iopub.status.idle":"2025-12-08T16:22:45.792492Z","shell.execute_reply.started":"2025-12-08T16:22:45.752975Z","shell.execute_reply":"2025-12-08T16:22:45.791545Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import Dataset\n\ntexts = test[\"text\"].tolist()\n\nencoded = tokenizer(\n    texts,\n    padding=True,\n    truncation=True,\n    max_length=max_len,\n    return_offsets_mapping=True,\n)\n\ntest_dataset = Dataset.from_dict({\n    \"input_ids\": encoded[\"input_ids\"],\n    \"attention_mask\": encoded[\"attention_mask\"],\n})\n\npred_output = trainer.predict(test_dataset)\n\nlogits = pred_output.predictions \npred_ids = logits.argmax(-1)\n\noffsets = np.array(encoded[\"offset_mapping\"])\nattn = np.array(encoded[\"attention_mask\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T16:33:04.314193Z","iopub.execute_input":"2025-12-08T16:33:04.314927Z","iopub.status.idle":"2025-12-08T16:33:17.886189Z","shell.execute_reply.started":"2025-12-08T16:33:04.314885Z","shell.execute_reply":"2025-12-08T16:33:17.885262Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_locations_strings = []\n\nfor i, text in enumerate(texts):\n    seq_ids = pred_ids[i]\n    seq_offsets = offsets[i]\n    seq_attn = attn[i]\n\n    spans = []\n    current_span = None\n\n    for token_id, (start, end), m in zip(seq_ids, seq_offsets, seq_attn):\n        if m == 0:\n            continue\n        if start == 0 and end == 0:\n            continue\n\n        label = id2label[int(token_id)]\n\n        if label.startswith(\"S-LOC\"):\n            if current_span is not None:\n                spans.append(current_span)\n            current_span = [start, end]\n        elif label.startswith(\"I-LOC\") and current_span is not None:\n            current_span[1] = end\n        else:\n            if current_span is not None:\n                spans.append(current_span)\n                current_span = None\n\n    if current_span is not None:\n        spans.append(current_span)\n\n    loc_strings = []\n    for (start, end) in spans:\n        loc = text[start:end].strip()\n        if loc:\n            loc_strings.append(loc)\n\n    unique_locs = list(dict.fromkeys(loc_strings))\n    locations_str = \", \".join(unique_locs)\n\n    all_locations_strings.append(locations_str)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T16:33:37.651870Z","iopub.execute_input":"2025-12-08T16:33:37.652475Z","iopub.status.idle":"2025-12-08T16:33:37.969563Z","shell.execute_reply.started":"2025-12-08T16:33:37.652453Z","shell.execute_reply":"2025-12-08T16:33:37.968914Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions = test[[\"text_id\", \"text\"]].copy()\npredictions[\"locations\"] = all_locations_strings\n\n# predictions.head()\npredictions[[\"text_id\", \"locations\"]].to_csv(\"baseline.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T16:34:01.660117Z","iopub.execute_input":"2025-12-08T16:34:01.660463Z","iopub.status.idle":"2025-12-08T16:34:01.697110Z","shell.execute_reply.started":"2025-12-08T16:34:01.660442Z","shell.execute_reply":"2025-12-08T16:34:01.696288Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n# Code Ends","metadata":{}}]}
